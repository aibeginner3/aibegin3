#!/usr/bin/env python
# -*- coding: utf-8 -*-

import pandas as pd

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer


def main():
    # データフレームを表示するときカラムを省略しない
    pd.set_option('display.max_columns', None)
    # 浮動小数点を表示するときは小数点以下 2 桁で揃える
    pd.options.display.float_format = '{:0.2f}'.format

    # 取り扱うコーパス
    corpus = [
        'This is the first document.',
        'This document is the second document.',
        'And this is the third one.',
        'Is this the first document?',
    ]

    # 単語の数をカウントする
    count_vectorizer = CountVectorizer()
    X_count = count_vectorizer.fit_transform(corpus)

    # 見やすさのために表示するときは pandas のデータフレームにする
    df = pd.DataFrame(data=X_count.toarray(),
                      columns=count_vectorizer.get_feature_names())
    print('--- BoW (Bag of Words) ---')
    print(df)

    # scikit-learn の TF-IDF 実装
    tfidf_vectorizer = TfidfVectorizer()
    X_tfidf = tfidf_vectorizer.fit_transform(corpus)

    # IDF を表示する
    print('--- IDF (Inverse Document Frequency) ---')
    df = pd.DataFrame(data=[tfidf_vectorizer.idf_],
                      columns=tfidf_vectorizer.get_feature_names())
    print(df)

    # TF-IDF を表示する
    print('--- TF-IDF ---')
    df = pd.DataFrame(data=X_tfidf.toarray(),
                      columns=tfidf_vectorizer.get_feature_names())
    print(df)


if __name__ == '__main__':
    main()




=======================================================================
$ python sktfidf.py 
--- BoW (Bag of Words) ---
   and  document  first  is  one  second  the  third  this
0    0         1      1   1    0       0    1      0     1
1    0         2      0   1    0       1    1      0     1
2    1         0      0   1    1       0    1      1     1
3    0         1      1   1    0       0    1      0     1
--- IDF (Inverse Document Frequency) ---
   and  document  first   is  one  second  the  third  this
0 1.92      1.22   1.51 1.00 1.92    1.92 1.00   1.92  1.00
--- TF-IDF ---
   and  document  first   is  one  second  the  third  this
0 0.00      0.47   0.58 0.38 0.00    0.00 0.38   0.00  0.38
1 0.00      0.69   0.00 0.28 0.00    0.54 0.28   0.00  0.28
2 0.51      0.00   0.00 0.27 0.51    0.00 0.27   0.51  0.27
3 0.00      0.47   0.58 0.38 0.00    0.00 0.38   0.00  0.38

=======================================================================
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import numpy as np
import pandas as pd

from sklearn.feature_extraction.text import CountVectorizer


def main():
    pd.set_option('display.max_columns', None)
    pd.options.display.float_format = '{:0.2f}'.format

    corpus = [
        'This is the first document.',
        'This document is the second document.',
        'And this is the third one.',
        'Is this the first document?',
    ]

    count_vectorizer = CountVectorizer()
    bow = count_vectorizer.fit_transform(corpus).toarray()
    print('--- BoW (Bag of Words) ---')
    df = pd.DataFrame(bow,
                      columns=count_vectorizer.get_feature_names())
    print(df)

    # TF を計算してるところ (行方向の処理)
    print('--- TF (Term Frequency) ---')
    # 文書に含まれる単語の数をカウントする
    number_of_words = np.sum(bow, axis=1, keepdims=True)
    # 文書の中での単語の頻度を計算する
    tf = bow / number_of_words
    df = pd.DataFrame(tf,
                      columns=count_vectorizer.get_feature_names())
    print(df)

    # IDF を計算してるところ (列方向の処理)
    print('--- IDF (Inverse Document Frequency) ---')
    # 文書の数をカウントする
    number_of_docs = len(corpus)
    # その単語が一つでも含まれる文書の数をカウントする
    number_of_docs_contain_word = np.count_nonzero(bow, axis=0)
    # 単語の珍しさを計算する
    idf = np.log(number_of_docs / number_of_docs_contain_word)
    df = pd.DataFrame([idf],
                      columns=count_vectorizer.get_feature_names())
    print(df)

    # TF-IDF を計算してるところ
    print('--- TF-IDF ---')
    # TF と IDF をかける
    tfidf = tf * idf
    df = pd.DataFrame(tfidf,
                      columns=count_vectorizer.get_feature_names())
    print(df)


if __name__ == '__main__':
    main()

=======================================================================
$ python mytfidf.py 
--- BoW (Bag of Words) ---
   and  document  first  is  one  second  the  third  this
0    0         1      1   1    0       0    1      0     1
1    0         2      0   1    0       1    1      0     1
2    1         0      0   1    1       0    1      1     1
3    0         1      1   1    0       0    1      0     1
--- TF (Term Frequency) ---
   and  document  first   is  one  second  the  third  this
0 0.00      0.20   0.20 0.20 0.00    0.00 0.20   0.00  0.20
1 0.00      0.33   0.00 0.17 0.00    0.17 0.17   0.00  0.17
2 0.17      0.00   0.00 0.17 0.17    0.00 0.17   0.17  0.17
3 0.00      0.20   0.20 0.20 0.00    0.00 0.20   0.00  0.20
--- IDF (Inverse Document Frequency) ---
   and  document  first   is  one  second  the  third  this
0 1.39      0.29   0.69 0.00 1.39    1.39 0.00   1.39  0.00
--- TF-IDF ---
   and  document  first   is  one  second  the  third  this
0 0.00      0.06   0.14 0.00 0.00    0.00 0.00   0.00  0.00
1 0.00      0.10   0.00 0.00 0.00    0.23 0.00   0.00  0.00
2 0.23      0.00   0.00 0.00 0.23    0.00 0.00   0.23  0.00
3 0.00      0.06   0.14 0.00 0.00    0.00 0.00   0.00  0.00

=======================================================================
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import numpy as np
import pandas as pd

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import normalize


def main():
    pd.set_option('display.max_columns', None)
    pd.options.display.float_format = '{:0.2f}'.format

    corpus = [
        'This is the first document.',
        'This document is the second document.',
        'And this is the third one.',
        'Is this the first document?',
    ]

    count_vectorizer = CountVectorizer()
    bow = count_vectorizer.fit_transform(corpus).toarray()
    print('--- BoW (Bag of Words) ---')
    df = pd.DataFrame(bow,
                      columns=count_vectorizer.get_feature_names())
    print(df)

    print('--- TF (Term Frequency) ---')
    number_of_words = np.sum(bow, axis=1, keepdims=True)
    tf = bow / number_of_words
    df = pd.DataFrame(tf,
                      columns=count_vectorizer.get_feature_names())
    print(df)

    print('--- IDF (Inverse Document Frequency) ---')
    # 文書の数に 1 を足す
    number_of_docs = len(corpus) + 1
    # 単語が含まれる文書の数にも 1 を足す
    number_of_docs_contain_word = np.count_nonzero(bow, axis=0) + 1
    # 最終的な IDF にも 1 を足す
    idf = np.log(number_of_docs / number_of_docs_contain_word) + 1
    df = pd.DataFrame([idf],
                      columns=count_vectorizer.get_feature_names())
    print(df)

    print('--- TF-IDF ---')
    # 結果を L2 で正規化する
    tfidf = normalize(tf * idf)
    df = pd.DataFrame(tfidf,
                      columns=count_vectorizer.get_feature_names())
    print(df)


if __name__ == '__main__':
    main()

=======================================================================
$ python compatfidf.py 
--- BoW (Bag of Words) ---
   and  document  first  is  one  second  the  third  this
0    0         1      1   1    0       0    1      0     1
1    0         2      0   1    0       1    1      0     1
2    1         0      0   1    1       0    1      1     1
3    0         1      1   1    0       0    1      0     1
--- TF (Term Frequency) ---
   and  document  first   is  one  second  the  third  this
0 0.00      0.20   0.20 0.20 0.00    0.00 0.20   0.00  0.20
1 0.00      0.33   0.00 0.17 0.00    0.17 0.17   0.00  0.17
2 0.17      0.00   0.00 0.17 0.17    0.00 0.17   0.17  0.17
3 0.00      0.20   0.20 0.20 0.00    0.00 0.20   0.00  0.20
--- IDF (Inverse Document Frequency) ---
   and  document  first   is  one  second  the  third  this
0 1.92      1.22   1.51 1.00 1.92    1.92 1.00   1.92  1.00
--- TF-IDF ---
   and  document  first   is  one  second  the  third  this
0 0.00      0.47   0.58 0.38 0.00    0.00 0.38   0.00  0.38
1 0.00      0.69   0.00 0.28 0.00    0.54 0.28   0.00  0.28
2 0.51      0.00   0.00 0.27 0.51    0.00 0.27   0.51  0.27
3 0.00      0.47   0.58 0.38 0.00    0.00 0.38   0.00  0.38

=======================================================================
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import pandas as pd

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer


def main():
    pd.set_option('display.max_columns', None)
    pd.options.display.float_format = '{:0.2f}'.format

    corpus = [
        'This is the first document.',
        'This document is the second document.',
        'And this is the third one.',
        'Is this the first document?',
    ]

    count_vectorizer = CountVectorizer()
    X_count = count_vectorizer.fit_transform(corpus)

    df = pd.DataFrame(data=X_count.toarray(),
                      columns=count_vectorizer.get_feature_names())
    print('--- BoW (Bag of Words) ---')
    print(df)

    # 正規化しないし Smooth もしない
    tfidf_vectorizer = TfidfVectorizer(norm=None,
                                       smooth_idf=False)
    X_tfidf = tfidf_vectorizer.fit_transform(corpus)

    print('--- IDF (Inverse Document Frequency) ---')
    df = pd.DataFrame(data=[tfidf_vectorizer.idf_],
                      columns=tfidf_vectorizer.get_feature_names())
    print(df)

    print('--- TF-IDF ---')
    df = pd.DataFrame(data=X_tfidf.toarray(),
                      columns=tfidf_vectorizer.get_feature_names())
    print(df)


if __name__ == '__main__':
    main()

=======================================================================
$ python nol2smooth.py 
--- BoW (Bag of Words) ---
   and  document  first  is  one  second  the  third  this
0    0         1      1   1    0       0    1      0     1
1    0         2      0   1    0       1    1      0     1
2    1         0      0   1    1       0    1      1     1
3    0         1      1   1    0       0    1      0     1
--- IDF (Inverse Document Frequency) ---
   and  document  first   is  one  second  the  third  this
0 2.39      1.29   1.69 1.00 2.39    2.39 1.00   2.39  1.00
--- TF-IDF ---
   and  document  first   is  one  second  the  third  this
0 0.00      1.29   1.69 1.00 0.00    0.00 1.00   0.00  1.00
1 0.00      2.58   0.00 1.00 0.00    2.39 1.00   0.00  1.00
2 2.39      0.00   0.00 1.00 2.39    0.00 1.00   2.39  1.00
3 0.00      1.29   1.69 1.00 0.00    0.00 1.00   0.00  1.00

=======================================================================
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import numpy as np
import pandas as pd

from sklearn.feature_extraction.text import CountVectorizer


def main():
    pd.set_option('display.max_columns', None)
    pd.options.display.float_format = '{:0.2f}'.format

    corpus = [
        'This is the first document.',
        'This document is the second document.',
        'And this is the third one.',
        'Is this the first document?',
    ]

    count_vectorizer = CountVectorizer()
    bow = count_vectorizer.fit_transform(corpus).toarray()
    print('--- BoW (Bag of Words) ---')
    df = pd.DataFrame(bow,
                      columns=count_vectorizer.get_feature_names())
    print(df)

    print('--- IDF (Inverse Document Frequency) ---')
    # 全ての単語が含まれる仮想的な文書を加えない
    number_of_docs = len(corpus)
    number_of_docs_contain_word = np.count_nonzero(bow, axis=0)
    idf = np.log(number_of_docs / number_of_docs_contain_word) + 1
    df = pd.DataFrame([idf],
                      columns=count_vectorizer.get_feature_names())
    print(df)

    print('--- TF-IDF ---')
    # BoW をそのまま使う (TF = Raw Frequency)
    tfidf = bow * idf
    df = pd.DataFrame(tfidf,
                      columns=count_vectorizer.get_feature_names())
    print(df)


if __name__ == '__main__':
    main()

=======================================================================
$ python mynol2smooth.py 
--- BoW (Bag of Words) ---
   and  document  first  is  one  second  the  third  this
0    0         1      1   1    0       0    1      0     1
1    0         2      0   1    0       1    1      0     1
2    1         0      0   1    1       0    1      1     1
3    0         1      1   1    0       0    1      0     1
--- IDF (Inverse Document Frequency) ---
   and  document  first   is  one  second  the  third  this
0 2.39      1.29   1.69 1.00 2.39    2.39 1.00   2.39  1.00
--- TF-IDF ---
   and  document  first   is  one  second  the  third  this
0 0.00      1.29   1.69 1.00 0.00    0.00 1.00   0.00  1.00
1 0.00      2.58   0.00 1.00 0.00    2.39 1.00   0.00  1.00
2 2.39      0.00   0.00 1.00 2.39    0.00 1.00   2.39  1.00
3 0.00      1.29   1.69 1.00 0.00    0.00 1.00   0.00  1.00

=======================================================================
=======================================================================
=======================================================================
=======================================================================
=======================================================================
